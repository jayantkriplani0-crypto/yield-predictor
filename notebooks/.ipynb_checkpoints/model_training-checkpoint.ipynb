{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AI-Powered Crop Yield Prediction - Model Training\n",
        "\n",
        "This notebook demonstrates the complete pipeline for training crop yield prediction models using synthetic agricultural data.\n",
        "\n",
        "## Overview\n",
        "- Load and explore crop yield data\n",
        "- Preprocess features (normalize per hectare, encode categoricals)\n",
        "- Train multiple models (Random Forest, XGBoost)\n",
        "- Evaluate performance and save best model\n",
        "- Generate feature importance plots\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import xgboost as xgb\n",
        "import joblib\n",
        "import shap\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load and Explore Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('../data/processed/train_small.csv')\n",
        "\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic dataset information\n",
        "print(\"Dataset Info:\")\n",
        "df.info()\n",
        "\n",
        "print(\"\\nDataset Description:\")\n",
        "df.describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "print(\"Missing values:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Check unique values in categorical columns\n",
        "print(\"\\nUnique values in categorical columns:\")\n",
        "categorical_cols = ['state', 'district', 'crop', 'season', 'soil_type', 'irrigation', 'seed_variety']\n",
        "for col in categorical_cols:\n",
        "    print(f\"{col}: {df[col].unique()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a copy for preprocessing\n",
        "df_processed = df.copy()\n",
        "\n",
        "# Normalize fertilizer and pesticide to per hectare\n",
        "df_processed['fertilizer_per_ha'] = df_processed['fertilizer'] / df_processed['area']\n",
        "df_processed['pesticide_per_ha'] = df_processed['pesticide'] / df_processed['area']\n",
        "\n",
        "print(\"Added normalized features:\")\n",
        "print(f\"Fertilizer per ha - Mean: {df_processed['fertilizer_per_ha'].mean():.2f}, Std: {df_processed['fertilizer_per_ha'].std():.2f}\")\n",
        "print(f\"Pesticide per ha - Mean: {df_processed['pesticide_per_ha'].mean():.2f}, Std: {df_processed['pesticide_per_ha'].std():.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define feature columns\n",
        "numeric_features = ['area', 'rainfall', 'temperature', 'fertilizer_per_ha', 'pesticide_per_ha']\n",
        "categorical_features = ['state', 'district', 'crop', 'season', 'soil_type', 'irrigation', 'seed_variety']\n",
        "\n",
        "# Create feature matrix X and target y\n",
        "X = df_processed[numeric_features + categorical_features]\n",
        "y = df_processed['yield']\n",
        "\n",
        "print(f\"Feature matrix shape: {X.shape}\")\n",
        "print(f\"Target shape: {y.shape}\")\n",
        "print(f\"Numeric features: {numeric_features}\")\n",
        "print(f\"Categorical features: {categorical_features}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create preprocessing pipeline\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numeric_features),\n",
        "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"Preprocessing pipeline created successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Model Training and Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data using time-based split (use year for temporal split)\n",
        "# Use 2020-2022 for training, 2023 for testing\n",
        "train_mask = df_processed['year'] <= 2022\n",
        "test_mask = df_processed['year'] > 2022\n",
        "\n",
        "X_train, X_test = X[train_mask], X[test_mask]\n",
        "y_train, y_test = y[train_mask], y[test_mask]\n",
        "\n",
        "print(f\"Training set: {X_train.shape[0]} samples\")\n",
        "print(f\"Test set: {X_test.shape[0]} samples\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create model pipelines\n",
        "rf_pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
        "])\n",
        "\n",
        "xgb_pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', xgb.XGBRegressor(n_estimators=100, random_state=42, verbosity=0))\n",
        "])\n",
        "\n",
        "print(\"Model pipelines created!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train models\n",
        "print(\"Training Random Forest...\")\n",
        "rf_pipeline.fit(X_train, y_train)\n",
        "\n",
        "print(\"Training XGBoost...\")\n",
        "xgb_pipeline.fit(X_train, y_train)\n",
        "\n",
        "print(\"Training completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate models\n",
        "def evaluate_model(model, X_test, y_test, model_name):\n",
        "    y_pred = model.predict(X_test)\n",
        "    \n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    \n",
        "    print(f\"\\n{model_name} Performance:\")\n",
        "    print(f\"MAE: {mae:.4f}\")\n",
        "    print(f\"RMSE: {rmse:.4f}\")\n",
        "    print(f\"R²: {r2:.4f}\")\n",
        "    \n",
        "    return {'mae': mae, 'rmse': rmse, 'r2': r2, 'predictions': y_pred}\n",
        "\n",
        "# Evaluate both models\n",
        "rf_results = evaluate_model(rf_pipeline, X_test, y_test, \"Random Forest\")\n",
        "xgb_results = evaluate_model(xgb_pipeline, X_test, y_test, \"XGBoost\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select best model based on R² score\n",
        "if rf_results['r2'] > xgb_results['r2']:\n",
        "    best_model = rf_pipeline\n",
        "    best_model_name = \"Random Forest\"\n",
        "    print(f\"\\nBest model: {best_model_name} (R² = {rf_results['r2']:.4f})\")\n",
        "else:\n",
        "    best_model = xgb_pipeline\n",
        "    best_model_name = \"XGBoost\"\n",
        "    print(f\"\\nBest model: {best_model_name} (R² = {xgb_results['r2']:.4f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Visualization and Feature Importance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create predicted vs actual plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Get predictions from best model\n",
        "y_pred_best = best_model.predict(X_test)\n",
        "\n",
        "plt.scatter(y_test, y_pred_best, alpha=0.7)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
        "plt.xlabel('Actual Yield (t/ha)')\n",
        "plt.ylabel('Predicted Yield (t/ha)')\n",
        "plt.title(f'Predicted vs Actual Yield - {best_model_name}')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Add R² score to plot\n",
        "r2_score_val = r2_score(y_test, y_pred_best)\n",
        "plt.text(0.05, 0.95, f'R² = {r2_score_val:.4f}', transform=plt.gca().transAxes, \n",
        "         bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature importance using SHAP (for tree-based models)\n",
        "if best_model_name == \"Random Forest\":\n",
        "    # For Random Forest, use built-in feature importance\n",
        "    feature_names = numeric_features + list(best_model.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(categorical_features))\n",
        "    importances = best_model.named_steps['regressor'].feature_importances_\n",
        "    \n",
        "    # Create feature importance plot\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    indices = np.argsort(importances)[::-1][:15]  # Top 15 features\n",
        "    \n",
        "    plt.title('Feature Importance - Random Forest')\n",
        "    plt.barh(range(len(indices)), importances[indices])\n",
        "    plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
        "    plt.xlabel('Feature Importance')\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "else:\n",
        "    # For XGBoost, use SHAP\n",
        "    try:\n",
        "        # Get transformed features\n",
        "        X_transformed = best_model.named_steps['preprocessor'].transform(X_test)\n",
        "        feature_names = numeric_features + list(best_model.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(categorical_features))\n",
        "        \n",
        "        # Create SHAP explainer\n",
        "        explainer = shap.TreeExplainer(best_model.named_steps['regressor'])\n",
        "        shap_values = explainer.shap_values(X_transformed)\n",
        "        \n",
        "        # Plot SHAP summary\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        shap.summary_plot(shap_values, X_transformed, feature_names=feature_names, show=False)\n",
        "        plt.title('SHAP Feature Importance - XGBoost')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"SHAP plot failed: {e}\")\n",
        "        print(\"Using built-in feature importance instead...\")\n",
        "        \n",
        "        # Fallback to built-in importance\n",
        "        feature_names = numeric_features + list(best_model.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(categorical_features))\n",
        "        importances = best_model.named_steps['regressor'].feature_importances_\n",
        "        \n",
        "        plt.figure(figsize=(12, 8))\n",
        "        indices = np.argsort(importances)[::-1][:15]\n",
        "        \n",
        "        plt.title('Feature Importance - XGBoost')\n",
        "        plt.barh(range(len(indices)), importances[indices])\n",
        "        plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
        "        plt.xlabel('Feature Importance')\n",
        "        plt.gca().invert_yaxis()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Save Model and Feature List\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the best model\n",
        "model_path = '../src/ml/models/yield_model.pkl'\n",
        "joblib.dump(best_model, model_path)\n",
        "print(f\"Model saved to: {model_path}\")\n",
        "\n",
        "# Save feature information\n",
        "feature_info = {\n",
        "    'numeric_features': numeric_features,\n",
        "    'categorical_features': categorical_features,\n",
        "    'all_features': numeric_features + categorical_features,\n",
        "    'target_column': 'yield'\n",
        "}\n",
        "\n",
        "feature_list_path = '../src/ml/models/feature_list.pkl'\n",
        "joblib.dump(feature_info, feature_list_path)\n",
        "print(f\"Feature list saved to: {feature_list_path}\")\n",
        "\n",
        "print(f\"\\nModel training completed successfully!\")\n",
        "print(f\"Best model: {best_model_name}\")\n",
        "print(f\"Test R² score: {r2_score(y_test, best_model.predict(X_test)):.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
